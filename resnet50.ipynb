{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"V28"},"accelerator":"TPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!conda install -y gdown","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9hTmihyvNV2R","executionInfo":{"status":"ok","timestamp":1720859467823,"user_tz":-60,"elapsed":25379,"user":{"displayName":"DYLAND BREL FONGANG MBE","userId":"12941330568412893829"}},"outputId":"32345c27-fd5f-4211-c2a3-cd47e45c97db","execution":{"iopub.status.busy":"2024-07-13T09:43:58.177190Z","iopub.execute_input":"2024-07-13T09:43:58.178011Z","iopub.status.idle":"2024-07-13T09:45:21.118844Z","shell.execute_reply.started":"2024-07-13T09:43:58.177971Z","shell.execute_reply":"2024-07-13T09:45:21.117869Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Retrieving notices: ...working... done\nChannels:\n - rapidsai\n - nvidia\n - conda-forge\n - defaults\n - pytorch\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda\n\n  added / updated specs:\n    - gdown\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    filelock-3.15.4            |     pyhd8ed1ab_0          17 KB  conda-forge\n    gdown-5.2.0                |     pyhd8ed1ab_0          21 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:          39 KB\n\nThe following NEW packages will be INSTALLED:\n\n  filelock           conda-forge/noarch::filelock-3.15.4-pyhd8ed1ab_0 \n  gdown              conda-forge/noarch::gdown-5.2.0-pyhd8ed1ab_0 \n\n\n\nDownloading and Extracting Packages:\ngdown-5.2.0          | 21 KB     |                                       |   0% \nfilelock-3.15.4      | 17 KB     |                                       |   0% \u001b[A\nfilelock-3.15.4      | 17 KB     | ##################################### | 100% \u001b[A\n                                                                                \u001b[A\n                                                                                \u001b[A\nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\n","output_type":"stream"}]},{"cell_type":"code","source":"# import gdown\n# url = \"https://drive.google.com/uc?id=1BT-8zitp3cv8hy9U6ulK7y4M_VQAO65y/view?usp=sharing\"\n\n# output = 'dataset.zip'\n# gdown.download(url, output)\n\n# Downloading the dataset archive\n!gdown --id 1BT-8zitp3cv8hy9U6ulK7y4M_VQAO65y\n\n!unzip dataset.zip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n\n# import keras\nfrom keras.models import load_model, Model\nfrom keras.models import Model\nfrom keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, ZeroPadding2D, MaxPooling2D, AveragePooling2D, Dense, Flatten, RandomRotation\nfrom keras.initializers import glorot_uniform\nfrom keras.utils import to_categorical\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n\nfrom PIL import Image\nimport numpy as np\nimport cv2 as cv\n\nfrom timeit import default_timer as timer\n","metadata":{"id":"RYLaAZK8NJD2","executionInfo":{"status":"ok","timestamp":1720860129523,"user_tz":-60,"elapsed":448,"user":{"displayName":"DYLAND BREL FONGANG MBE","userId":"12941330568412893829"}},"execution":{"iopub.status.busy":"2024-07-13T09:45:28.137553Z","iopub.execute_input":"2024-07-13T09:45:28.137878Z","iopub.status.idle":"2024-07-13T09:45:39.528161Z","shell.execute_reply.started":"2024-07-13T09:45:28.137848Z","shell.execute_reply":"2024-07-13T09:45:39.527222Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-07-13 09:45:29.730335: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-13 09:45:29.730450: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-13 09:45:29.840290: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset_path = \"./dataset\"","metadata":{"id":"4Z2FjWVOOzAU","executionInfo":{"status":"ok","timestamp":1720859726057,"user_tz":-60,"elapsed":450,"user":{"displayName":"DYLAND BREL FONGANG MBE","userId":"12941330568412893829"}},"execution":{"iopub.status.busy":"2024-07-13T09:45:39.530265Z","iopub.execute_input":"2024-07-13T09:45:39.530774Z","iopub.status.idle":"2024-07-13T09:45:39.537023Z","shell.execute_reply.started":"2024-07-13T09:45:39.530748Z","shell.execute_reply":"2024-07-13T09:45:39.535677Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Labels","metadata":{"id":"0PnaO5PdNJD4"}},{"cell_type":"code","source":"# The labels are hardcoded for test purpose only, not for production intends\n\n\nlabels_file = open(os.path.join(dataset_path, \"labels.data\"), \"r\")\nLABELS = {name:idx for idx, name in enumerate(labels_file.read().split('\\n'))}\n\nlabels_file.close()\n\nREVERSED_LABELS = {_[0]:_[1] for _ in [(value, key) for key, value in LABELS.items()]}\n","metadata":{"id":"MV1FmyvvNJD6","executionInfo":{"status":"ok","timestamp":1720859737982,"user_tz":-60,"elapsed":3,"user":{"displayName":"DYLAND BREL FONGANG MBE","userId":"12941330568412893829"}},"execution":{"iopub.status.busy":"2024-07-13T09:45:39.538694Z","iopub.execute_input":"2024-07-13T09:45:39.539945Z","iopub.status.idle":"2024-07-13T09:45:39.550066Z","shell.execute_reply.started":"2024-07-13T09:45:39.539893Z","shell.execute_reply":"2024-07-13T09:45:39.549306Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Dataset loading functions","metadata":{"id":"c2b5GIUrNJD6"}},{"cell_type":"code","source":"\nface_classifier = cv.CascadeClassifier(cv.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n\ndef save_bounding_box(img:Image.Image, path:str, shape:tuple):\n\n    img_mat = cv.cvtColor(np.array(img), cv.COLOR_RGB2BGR)\n    gray_img = cv.cvtColor(img_mat, cv.COLOR_BGR2GRAY)\n\n    faces = face_classifier.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=5, minSize=(40, 40))\n\n    faces_to_return = []\n    root_pos = path.rfind('.')\n    index = 0\n    for (x, y, w, h) in faces:\n\n        to_save = cv.resize(img_mat[y:y+h, x:x+w], shape)\n\n        cv.imwrite(\n           path[:root_pos] + str(index) + path[root_pos:],\n           to_save\n        )\n        index += 1\n\n        faces_to_return.append(Image.fromarray(cv.cvtColor(to_save, cv.COLOR_BGR2RGB)))\n\n    return faces_to_return\n\n\n\n\ndef load(dir:str, shape:tuple=(224,224)) -> tuple:\n\n    # Loading dataset\n    data = []\n    labels = []\n\n    dir_content = os.listdir(dir)\n\n    for person_folder in dir_content: # For each person's folder\n\n        for _ in os.listdir(os.path.join(dir, person_folder)): # For face image in a person's folder\n\n            if '.' in _: # If _ is actually a file\n                file = Image.open(os.path.join(dir, person_folder, _))\n\n                # If the loaded image doesn't meet the shape standards (maybe not cropped yet) we do so,\n                # save the cropped version before adding to the dataset\n                if file.size != shape:\n                    # faces is a list consisting of Image objects of all the faces extrated in the current file\n                    faces = save_bounding_box(file, os.path.join(dir, _), shape)\n\n                    # Adding the face(s)\n                    for f in faces:\n\n                        data.append(np.asarray(f))\n\n                        # Adding the label\n                        for key in LABELS.keys():\n                            if key in _:\n                                labels.append(LABELS[key])\n                                break\n\n                    # Moving the old parent image\n                    os.system(\"mkdir \" + os.path.join(dir, \"old_images\").replace('/', '\\\\'))\n                    # print(('move \"' + os.path.join(dir, _) + '\" \"' + os.path.join(dir, \"old_images/\")).replace('/', '\\\\') + '\"')\n                    os.system(('move \"' + os.path.join(dir, _) + '\" \"' + os.path.join(dir, \"old_images/\")).replace('/', '\\\\') + '\"')\n\n                else:\n\n                    # Adding the file\n                    data.append(np.asarray(file))\n\n                    # Adding the label\n                    for key in LABELS.keys():\n                        if key.lower() == person_folder.lower() or person_folder.lower() in key.lower():\n                            labels.append(LABELS[key])\n                            break\n\n\n    return np.array(data), to_categorical(labels)\n\n\ndef load_data(path:str=\"./dataset\") -> tuple:\n\n    train_data_path = os.path.join(path, \"train_data\")\n    test_data_path = os.path.join(path, \"test_data\")\n\n    # Loading training dataset\n    train_data = load(train_data_path)\n    # Loading training dataset\n    test_data = load(test_data_path)\n\n    return train_data, test_data\n\n\n\n\nclass TimingCallback(Callback):\n\n    def __init__(self, logs={}):\n        self.logs = []\n\n    def on_epoch_begin(self, epoch, logs={}):\n        self.starttime = timer()\n\n    def on_epoch_end(self, epoch, logs=None):\n        self.logs.append(timer() - self.starttime)\n","metadata":{"id":"c7AZYBgONJD6","executionInfo":{"status":"ok","timestamp":1720860133728,"user_tz":-60,"elapsed":481,"user":{"displayName":"DYLAND BREL FONGANG MBE","userId":"12941330568412893829"}},"execution":{"iopub.status.busy":"2024-07-13T09:45:39.551468Z","iopub.execute_input":"2024-07-13T09:45:39.551770Z","iopub.status.idle":"2024-07-13T09:45:39.601228Z","shell.execute_reply.started":"2024-07-13T09:45:39.551746Z","shell.execute_reply":"2024-07-13T09:45:39.600503Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Model implementation, loading and saving functions","metadata":{"id":"hw04VwsNNJD7"}},{"cell_type":"code","source":"\n#Implementation of convolution block\ndef convolutional_block(X, f, filters, stage, block, s):\n\n    F1, F2, F3 = filters\n    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3)(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3)(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3)(X)\n    X = Activation('relu')(X)\n\n    return X\n\n\n\n#Implementation of Identity Block\n\ndef identity_block(X, f, filters, stage, block):\n\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    F1, F2, F3 = filters\n\n    X_shortcut = X\n\n    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n\n    # Skip Connection\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n\n    return X\n\n\n\n\n#Implementation of ResNet-50\n\n#Implementation of ResNet-50\ndef ResNet50(input_shape=(224, 224, 3)):\n\n    X_input = Input(input_shape)\n\n    # Data augmentation, clockwise rotation\n    X = RandomRotation(1)(X_input)\n\n    X = ZeroPadding2D((3, 3))(X)\n\n    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n    X = convolutional_block(X, f=3, filters=[16, 16, 64], stage=2, block='a', s=1)\n    X = identity_block(X, 3, [16, 16, 64], stage=2, block='a')\n    X = identity_block(X, 3, [16, 16, 64], stage=2, block='b')\n    X = identity_block(X, 3, [16, 16, 64], stage=2, block='c')\n    # X = identity_block(X, 3, [16, 16, 64], stage=2, block='d')\n\n\n    X = convolutional_block(X, f=3, filters=[32, 32, 128], stage=3, block='b', s=2)\n    X = identity_block(X, 3, [32, 32, 128], stage=3, block='a')\n    X = identity_block(X, 3, [32, 32, 128], stage=3, block='b')\n    # X = identity_block(X, 3, [32, 32, 128], stage=3, block='c')\n    # X = identity_block(X, 3, [32, 32, 128], stage=3, block='d')\n\n    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=4, block='c', s=2)\n    X = identity_block(X, 3, [64, 64, 256], stage=4, block='a')\n    # X = identity_block(X, 3, [64, 64, 256], stage=4, block='b')\n    # X = identity_block(X, 3, [64, 64, 256], stage=4, block='c')\n    # X = identity_block(X, 3, [64, 64, 256], stage=4, block='d')\n    # X = identity_block(X, 3, [64, 64, 256], stage=4, block='e')\n    # X = identity_block(X, 3, [64, 64, 256], stage=4, block='f')\n\n    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=5, block='d', s=2)\n    # X = identity_block(X, 3, [128, 128, 512], stage=5, block='a')\n    # X = identity_block(X, 3, [128, 128, 512], stage=5, block='c')\n\n    # Replacing the GAP with Flatten and Dense layers\n    # X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n#     X = Flatten()(X)\n#     X = Dense(64, activation='relu', name='fc0',kernel_initializer=glorot_uniform(seed=0))(X)\n\n    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n\n    return model\n\n\n\n\ndef create_model() -> Model:\n\n    base_model = ResNet50(input_shape=(224, 224, 3))\n    x = base_model.output\n    x = Flatten()(x)\n    x = Dense(128, activation='relu', name='fc1',kernel_initializer=glorot_uniform(seed=0))(x)\n    x = Dense(64, activation='relu', name='fc2',kernel_initializer=glorot_uniform(seed=0))(x)\n    x = Dense(33, activation='softmax', name='fc3',kernel_initializer=glorot_uniform(seed=0))(x)\n\n    model = Model(inputs=base_model.input, outputs=x)\n\n#     for layer in base_model.layers:\n#         layer.trainable = False\n\n    return model\n\n\ndef save_model(model:Model):\n\n    model.save(\"base_model_og.keras\")\n\ndef load_weights():\n\n    return load_model(\"base_model_og.keras\")\n","metadata":{"id":"TF8C7SE7NJD7","executionInfo":{"status":"ok","timestamp":1720860374946,"user_tz":-60,"elapsed":640,"user":{"displayName":"DYLAND BREL FONGANG MBE","userId":"12941330568412893829"}},"execution":{"iopub.status.busy":"2024-07-13T10:19:17.219314Z","iopub.execute_input":"2024-07-13T10:19:17.220423Z","iopub.status.idle":"2024-07-13T10:19:17.250710Z","shell.execute_reply.started":"2024-07-13T10:19:17.220376Z","shell.execute_reply":"2024-07-13T10:19:17.249692Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# Training phase","metadata":{"id":"RhfwnxSMNJD8"}},{"cell_type":"markdown","source":"## Loading the dataset","metadata":{"id":"QDautas-QoQw"}},{"cell_type":"code","source":"print('\\nLoading the dataset ...')\n(X_train, y_train), (X_test, y_test) = load_data(dataset_path)\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lH_ret1ZQrjD","executionInfo":{"status":"ok","timestamp":1720860400396,"user_tz":-60,"elapsed":2726,"user":{"displayName":"DYLAND BREL FONGANG MBE","userId":"12941330568412893829"}},"outputId":"50923c6c-0ed6-4c72-d946-d52ae5b15a5c","execution":{"iopub.status.busy":"2024-07-13T09:45:39.630432Z","iopub.execute_input":"2024-07-13T09:45:39.630760Z","iopub.status.idle":"2024-07-13T09:45:41.622754Z","shell.execute_reply.started":"2024-07-13T09:45:39.630730Z","shell.execute_reply":"2024-07-13T09:45:41.621793Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\nLoading the dataset ...\n(2053, 224, 224, 3) (2053, 33)\n(620, 224, 224, 3) (620, 33)\n","output_type":"stream"}]},{"cell_type":"code","source":"mkdir models","metadata":{"execution":{"iopub.status.busy":"2024-07-13T09:45:41.624121Z","iopub.execute_input":"2024-07-13T09:45:41.624505Z","iopub.status.idle":"2024-07-13T09:45:42.694187Z","shell.execute_reply.started":"2024-07-13T09:45:41.624471Z","shell.execute_reply":"2024-07-13T09:45:42.693144Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"}]},{"cell_type":"code","source":"\nprint('\\nLoading the model ...')\nmodel = create_model()\n\nprint('\\nCompiling the model ...')\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Callbacks\ntime = TimingCallback()\nfilepath = \"models/resnet50-{epoch}-loss-{loss:.2f}-accuracy-{accuracy:.2f}-val_accuracy-{val_accuracy:.2f}.keras\"\n# checkpoint = ModelCheckpoint(filepath, monitor=\"accuracy\", verbose=1, save_best_only=True, mode='max')\ncheckpoint1 = ModelCheckpoint(filepath, monitor=\"val_accuracy\", verbose=1, save_best_only=True, mode='max')\nearlystop = EarlyStopping(monitor=\"val_accuracy\", patience=20)\n\n\ncallbacks_list = [checkpoint1, time, earlystop]\n\nmodel.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, shuffle=True, callbacks=callbacks_list)\n\nprint(f\"\\nEnd of training.\\nThe training lasted: {sum(time.logs)} s.\")\n\nprint(\"\\nSaving...\")\nsave_model(model)\n\nprint('\\nModel saved.')\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"id":"e5gdvYcNNJD8","executionInfo":{"status":"error","timestamp":1720860461731,"user_tz":-60,"elapsed":467,"user":{"displayName":"DYLAND BREL FONGANG MBE","userId":"12941330568412893829"}},"outputId":"c6a60041-ca0b-4d34-b346-788e26df6e17","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Saving the feature extraction part","metadata":{}},{"cell_type":"code","source":"\noutput = None\n\nfor layer in model.layers:\n    if isinstance(layer, Flatten):\n        output = layer.output\n\n\nif output:\n    new_model = Model(inputs=model.input, outputs=output)\n\n    new_model.save(\"FExtractor.keras\")\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    print(new_model.summary())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}