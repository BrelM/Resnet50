{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Optimization of Resnet50 based on Flatten and Dense layer insertion for facial recognition applied to a voting system "]},{"cell_type":"markdown","metadata":{},"source":["This notebook is divided in two parts:<br>\n","* A Model training part: If you wish to train your own model\n","* A User part: To simulate the voting system\n"]},{"cell_type":"markdown","metadata":{},"source":["## Model training"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-07-13T09:43:58.178011Z","iopub.status.busy":"2024-07-13T09:43:58.177190Z","iopub.status.idle":"2024-07-13T09:45:21.118844Z","shell.execute_reply":"2024-07-13T09:45:21.117869Z","shell.execute_reply.started":"2024-07-13T09:43:58.177971Z"},"executionInfo":{"elapsed":25379,"status":"ok","timestamp":1720859467823,"user":{"displayName":"DYLAND BREL FONGANG MBE","userId":"12941330568412893829"},"user_tz":-60},"id":"9hTmihyvNV2R","outputId":"32345c27-fd5f-4211-c2a3-cd47e45c97db","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Retrieving notices: ...working... done\n","Channels:\n"," - rapidsai\n"," - nvidia\n"," - conda-forge\n"," - defaults\n"," - pytorch\n","Platform: linux-64\n","Collecting package metadata (repodata.json): done\n","Solving environment: done\n","\n","## Package Plan ##\n","\n","  environment location: /opt/conda\n","\n","  added / updated specs:\n","    - gdown\n","\n","\n","The following packages will be downloaded:\n","\n","    package                    |            build\n","    ---------------------------|-----------------\n","    filelock-3.15.4            |     pyhd8ed1ab_0          17 KB  conda-forge\n","    gdown-5.2.0                |     pyhd8ed1ab_0          21 KB  conda-forge\n","    ------------------------------------------------------------\n","                                           Total:          39 KB\n","\n","The following NEW packages will be INSTALLED:\n","\n","  filelock           conda-forge/noarch::filelock-3.15.4-pyhd8ed1ab_0 \n","  gdown              conda-forge/noarch::gdown-5.2.0-pyhd8ed1ab_0 \n","\n","\n","\n","Downloading and Extracting Packages:\n","gdown-5.2.0          | 21 KB     |                                       |   0% \n","filelock-3.15.4      | 17 KB     |                                       |   0% \u001b[A\n","filelock-3.15.4      | 17 KB     | ##################################### | 100% \u001b[A\n","                                                                                \u001b[A\n","                                                                                \u001b[A\n","Preparing transaction: done\n","Verifying transaction: done\n","Executing transaction: done\n"]}],"source":["!conda install -y gdown"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# import gdown\n","# url = \"https://drive.google.com/uc?id=1BT-8zitp3cv8hy9U6ulK7y4M_VQAO65y/view?usp=sharing\"\n","\n","# output = 'dataset.zip'\n","# gdown.download(url, output)\n","\n","# Downloading the dataset archive\n","!gdown --id 1BT-8zitp3cv8hy9U6ulK7y4M_VQAO65y\n","\n","!unzip dataset.zip"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-13T09:45:28.137878Z","iopub.status.busy":"2024-07-13T09:45:28.137553Z","iopub.status.idle":"2024-07-13T09:45:39.528161Z","shell.execute_reply":"2024-07-13T09:45:39.527222Z","shell.execute_reply.started":"2024-07-13T09:45:28.137848Z"},"executionInfo":{"elapsed":448,"status":"ok","timestamp":1720860129523,"user":{"displayName":"DYLAND BREL FONGANG MBE","userId":"12941330568412893829"},"user_tz":-60},"id":"RYLaAZK8NJD2","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-07-13 09:45:29.730335: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-07-13 09:45:29.730450: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-07-13 09:45:29.840290: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import os\n","os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n","\n","# Uncomment the following line if you have a GPU device and wish to use it\n","# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n","\n","\n","# import keras\n","from keras.models import load_model, Model\n","from keras.models import Model\n","from keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, ZeroPadding2D, MaxPooling2D, AveragePooling2D, Dense, Flatten, RandomRotation\n","from keras.initializers import glorot_uniform\n","from keras.utils import to_categorical\n","from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n","\n","from PIL import Image\n","import numpy as np\n","import cv2 as cv\n","\n","from timeit import default_timer as timer\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-13T09:45:39.530774Z","iopub.status.busy":"2024-07-13T09:45:39.530265Z","iopub.status.idle":"2024-07-13T09:45:39.537023Z","shell.execute_reply":"2024-07-13T09:45:39.535677Z","shell.execute_reply.started":"2024-07-13T09:45:39.530748Z"},"executionInfo":{"elapsed":450,"status":"ok","timestamp":1720859726057,"user":{"displayName":"DYLAND BREL FONGANG MBE","userId":"12941330568412893829"},"user_tz":-60},"id":"4Z2FjWVOOzAU","trusted":true},"outputs":[],"source":["dataset_path = \"./dataset\""]},{"cell_type":"markdown","metadata":{"id":"0PnaO5PdNJD4"},"source":["### Labels"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-13T09:45:39.539945Z","iopub.status.busy":"2024-07-13T09:45:39.538694Z","iopub.status.idle":"2024-07-13T09:45:39.550066Z","shell.execute_reply":"2024-07-13T09:45:39.549306Z","shell.execute_reply.started":"2024-07-13T09:45:39.539893Z"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1720859737982,"user":{"displayName":"DYLAND BREL FONGANG MBE","userId":"12941330568412893829"},"user_tz":-60},"id":"MV1FmyvvNJD6","trusted":true},"outputs":[],"source":["# The labels are hardcoded for test purpose only, not for production intends\n","\n","\n","labels_file = open(os.path.join(dataset_path, \"labels.data\"), \"r\")\n","LABELS = {name:idx for idx, name in enumerate(labels_file.read().split('\\n'))}\n","\n","labels_file.close()\n","\n","REVERSED_LABELS = {_[0]:_[1] for _ in [(value, key) for key, value in LABELS.items()]}\n"]},{"cell_type":"markdown","metadata":{"id":"c2b5GIUrNJD6"},"source":["### Dataset loading functions"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-13T09:45:39.551770Z","iopub.status.busy":"2024-07-13T09:45:39.551468Z","iopub.status.idle":"2024-07-13T09:45:39.601228Z","shell.execute_reply":"2024-07-13T09:45:39.600503Z","shell.execute_reply.started":"2024-07-13T09:45:39.551746Z"},"executionInfo":{"elapsed":481,"status":"ok","timestamp":1720860133728,"user":{"displayName":"DYLAND BREL FONGANG MBE","userId":"12941330568412893829"},"user_tz":-60},"id":"c7AZYBgONJD6","trusted":true},"outputs":[],"source":["\n","face_classifier = cv.CascadeClassifier(cv.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n","\n","def save_bounding_box(img:Image.Image, path:str, shape:tuple):\n","\n","    img_mat = cv.cvtColor(np.array(img), cv.COLOR_RGB2BGR)\n","    gray_img = cv.cvtColor(img_mat, cv.COLOR_BGR2GRAY)\n","\n","    faces = face_classifier.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=5, minSize=(40, 40))\n","\n","    faces_to_return = []\n","    root_pos = path.rfind('.')\n","    index = 0\n","    for (x, y, w, h) in faces:\n","\n","        to_save = cv.resize(img_mat[y:y+h, x:x+w], shape)\n","\n","        cv.imwrite(\n","           path[:root_pos] + str(index) + path[root_pos:],\n","           to_save\n","        )\n","        index += 1\n","\n","        faces_to_return.append(Image.fromarray(cv.cvtColor(to_save, cv.COLOR_BGR2RGB)))\n","\n","    return faces_to_return\n","\n","\n","\n","\n","def load(dir:str, shape:tuple=(224,224)) -> tuple:\n","\n","    # Loading dataset\n","    data = []\n","    labels = []\n","\n","    dir_content = os.listdir(dir)\n","\n","    for person_folder in dir_content: # For each person's folder\n","\n","        for _ in os.listdir(os.path.join(dir, person_folder)): # For face image in a person's folder\n","\n","            if '.' in _: # If _ is actually a file\n","                file = Image.open(os.path.join(dir, person_folder, _))\n","\n","                # If the loaded image doesn't meet the shape standards (maybe not cropped yet) we do so,\n","                # save the cropped version before adding to the dataset\n","                if file.size != shape:\n","                    # faces is a list consisting of Image objects of all the faces extrated in the current file\n","                    faces = save_bounding_box(file, os.path.join(dir, _), shape)\n","\n","                    # Adding the face(s)\n","                    for f in faces:\n","\n","                        data.append(np.asarray(f))\n","\n","                        # Adding the label\n","                        for key in LABELS.keys():\n","                            if key in _:\n","                                labels.append(LABELS[key])\n","                                break\n","\n","                    # Moving the old parent image\n","                    os.system(\"mkdir \" + os.path.join(dir, \"old_images\").replace('/', '\\\\'))\n","                    # print(('move \"' + os.path.join(dir, _) + '\" \"' + os.path.join(dir, \"old_images/\")).replace('/', '\\\\') + '\"')\n","                    os.system(('move \"' + os.path.join(dir, _) + '\" \"' + os.path.join(dir, \"old_images/\")).replace('/', '\\\\') + '\"')\n","\n","                else:\n","\n","                    # Adding the file\n","                    data.append(np.asarray(file))\n","\n","                    # Adding the label\n","                    for key in LABELS.keys():\n","                        if key.lower() == person_folder.lower() or person_folder.lower() in key.lower():\n","                            labels.append(LABELS[key])\n","                            break\n","\n","\n","    return np.array(data), to_categorical(labels)\n","\n","\n","def load_data(path:str=\"./dataset\") -> tuple:\n","\n","    train_data_path = os.path.join(path, \"train_data\")\n","    test_data_path = os.path.join(path, \"test_data\")\n","\n","    # Loading training dataset\n","    train_data = load(train_data_path)\n","    # Loading training dataset\n","    test_data = load(test_data_path)\n","\n","    return train_data, test_data\n","\n","\n","\n","\n","class TimingCallback(Callback):\n","\n","    def __init__(self, logs={}):\n","        self.logs = []\n","\n","    def on_epoch_begin(self, epoch, logs={}):\n","        self.starttime = timer()\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        self.logs.append(timer() - self.starttime)\n"]},{"cell_type":"markdown","metadata":{"id":"hw04VwsNNJD7"},"source":["### Model implementation, loading and saving functions"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-07-13T10:19:17.220423Z","iopub.status.busy":"2024-07-13T10:19:17.219314Z","iopub.status.idle":"2024-07-13T10:19:17.250710Z","shell.execute_reply":"2024-07-13T10:19:17.249692Z","shell.execute_reply.started":"2024-07-13T10:19:17.220376Z"},"executionInfo":{"elapsed":640,"status":"ok","timestamp":1720860374946,"user":{"displayName":"DYLAND BREL FONGANG MBE","userId":"12941330568412893829"},"user_tz":-60},"id":"TF8C7SE7NJD7","trusted":true},"outputs":[],"source":["\n","#Implementation of convolution block\n","def convolutional_block(X, f, filters, stage, block, s):\n","\n","    F1, F2, F3 = filters\n","    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_initializer=glorot_uniform(seed=0))(X)\n","    X = BatchNormalization(axis=3)(X)\n","    X = Activation('relu')(X)\n","\n","    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', kernel_initializer=glorot_uniform(seed=0))(X)\n","    X = BatchNormalization(axis=3)(X)\n","    X = Activation('relu')(X)\n","\n","    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_initializer=glorot_uniform(seed=0))(X)\n","    X = BatchNormalization(axis=3)(X)\n","    X = Activation('relu')(X)\n","\n","    return X\n","\n","\n","\n","#Implementation of Identity Block\n","\n","def identity_block(X, f, filters, stage, block):\n","\n","    conv_name_base = 'res' + str(stage) + block + '_branch'\n","    bn_name_base = 'bn' + str(stage) + block + '_branch'\n","    F1, F2, F3 = filters\n","\n","    X_shortcut = X\n","\n","    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n","    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n","    X = Activation('relu')(X)\n","\n","    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n","    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n","    X = Activation('relu')(X)\n","\n","    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n","    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n","\n","    # Skip Connection\n","    X = Add()([X, X_shortcut])\n","    X = Activation('relu')(X)\n","\n","    return X\n","\n","\n","\n","\n","#Implementation of ResNet-50\n","\n","#Implementation of ResNet-50\n","def ResNet50(input_shape=(224, 224, 3)):\n","\n","    X_input = Input(input_shape)\n","\n","    # Data augmentation, clockwise rotation\n","    X = RandomRotation(1)(X_input)\n","\n","    X = ZeroPadding2D((3, 3))(X)\n","\n","    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n","    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n","    X = Activation('relu')(X)\n","    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n","\n","    X = convolutional_block(X, f=3, filters=[16, 16, 64], stage=2, block='a', s=1)\n","    X = identity_block(X, 3, [16, 16, 64], stage=2, block='a')\n","    X = identity_block(X, 3, [16, 16, 64], stage=2, block='b')\n","    X = identity_block(X, 3, [16, 16, 64], stage=2, block='c')\n","    # X = identity_block(X, 3, [16, 16, 64], stage=2, block='d')\n","\n","\n","    X = convolutional_block(X, f=3, filters=[32, 32, 128], stage=3, block='b', s=2)\n","    X = identity_block(X, 3, [32, 32, 128], stage=3, block='a')\n","    X = identity_block(X, 3, [32, 32, 128], stage=3, block='b')\n","    # X = identity_block(X, 3, [32, 32, 128], stage=3, block='c')\n","    # X = identity_block(X, 3, [32, 32, 128], stage=3, block='d')\n","\n","    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=4, block='c', s=2)\n","    X = identity_block(X, 3, [64, 64, 256], stage=4, block='a')\n","    # X = identity_block(X, 3, [64, 64, 256], stage=4, block='b')\n","    # X = identity_block(X, 3, [64, 64, 256], stage=4, block='c')\n","    # X = identity_block(X, 3, [64, 64, 256], stage=4, block='d')\n","    # X = identity_block(X, 3, [64, 64, 256], stage=4, block='e')\n","    # X = identity_block(X, 3, [64, 64, 256], stage=4, block='f')\n","\n","    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=5, block='d', s=2)\n","    # X = identity_block(X, 3, [128, 128, 512], stage=5, block='a')\n","    # X = identity_block(X, 3, [128, 128, 512], stage=5, block='c')\n","\n","    # Replacing the GAP with Flatten and Dense layers\n","    # X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n","#     X = Dense(64, activation='relu', name='fc0',kernel_initializer=glorot_uniform(seed=0))(X)\n","\n","    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n","\n","    return model\n","\n","\n","\n","\n","def create_model() -> Model:\n","\n","    base_model = ResNet50(input_shape=(224, 224, 3))\n","    x = base_model.output\n","    x = Flatten()(x)\n","    x = Dense(128, activation='relu', name='fc1',kernel_initializer=glorot_uniform(seed=0))(x)\n","    x = Dense(64, activation='relu', name='fc2',kernel_initializer=glorot_uniform(seed=0))(x)\n","    x = Dense(33, activation='softmax', name='fc3',kernel_initializer=glorot_uniform(seed=0))(x)\n","\n","    model = Model(inputs=base_model.input, outputs=x)\n","\n","#     for layer in base_model.layers:\n","#         layer.trainable = False\n","\n","    return model\n","\n","\n","def save_model(model:Model):\n","\n","    model.save(\"base_model_og.keras\")\n","\n","def load_weights():\n","\n","    return load_model(\"base_model_og.keras\")\n"]},{"cell_type":"markdown","metadata":{"id":"RhfwnxSMNJD8"},"source":["### Training phase"]},{"cell_type":"markdown","metadata":{"id":"QDautas-QoQw"},"source":["#### Loading the dataset"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-07-13T09:45:39.630760Z","iopub.status.busy":"2024-07-13T09:45:39.630432Z","iopub.status.idle":"2024-07-13T09:45:41.622754Z","shell.execute_reply":"2024-07-13T09:45:41.621793Z","shell.execute_reply.started":"2024-07-13T09:45:39.630730Z"},"executionInfo":{"elapsed":2726,"status":"ok","timestamp":1720860400396,"user":{"displayName":"DYLAND BREL FONGANG MBE","userId":"12941330568412893829"},"user_tz":-60},"id":"lH_ret1ZQrjD","outputId":"50923c6c-0ed6-4c72-d946-d52ae5b15a5c","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Loading the dataset ...\n","(2053, 224, 224, 3) (2053, 33)\n","(620, 224, 224, 3) (620, 33)\n"]}],"source":["print('\\nLoading the dataset ...')\n","(X_train, y_train), (X_test, y_test) = load_data(dataset_path)\n","print(X_train.shape, y_train.shape)\n","print(X_test.shape, y_test.shape)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-07-13T09:45:41.624505Z","iopub.status.busy":"2024-07-13T09:45:41.624121Z","iopub.status.idle":"2024-07-13T09:45:42.694187Z","shell.execute_reply":"2024-07-13T09:45:42.693144Z","shell.execute_reply.started":"2024-07-13T09:45:41.624471Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid, fd = os.forkpty()\n"]}],"source":["mkdir models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"executionInfo":{"elapsed":467,"status":"error","timestamp":1720860461731,"user":{"displayName":"DYLAND BREL FONGANG MBE","userId":"12941330568412893829"},"user_tz":-60},"id":"e5gdvYcNNJD8","outputId":"c6a60041-ca0b-4d34-b346-788e26df6e17","trusted":true},"outputs":[],"source":["\n","print('\\nLoading the model ...')\n","model = create_model()\n","\n","print('\\nCompiling the model ...')\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Callbacks\n","time = TimingCallback()\n","filepath = \"models/resnet50-{epoch}-loss-{loss:.2f}-accuracy-{accuracy:.2f}-val_accuracy-{val_accuracy:.2f}.keras\"\n","# checkpoint = ModelCheckpoint(filepath, monitor=\"accuracy\", verbose=1, save_best_only=True, mode='max')\n","checkpoint1 = ModelCheckpoint(filepath, monitor=\"val_accuracy\", verbose=1, save_best_only=True, mode='max')\n","earlystop = EarlyStopping(monitor=\"val_accuracy\", patience=20)\n","\n","\n","callbacks_list = [checkpoint1, time, earlystop]\n","\n","model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, shuffle=True, callbacks=callbacks_list)\n","\n","print(f\"\\nEnd of training.\\nThe training lasted: {sum(time.logs)} s.\")\n","\n","print(\"\\nSaving...\")\n","save_model(model)\n","\n","print('\\nModel saved.')\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Saving the feature extraction part"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","output = None\n","\n","for layer in model.layers:\n","    if isinstance(layer, Flatten):\n","        output = layer.output\n","\n","\n","if output:\n","    new_model = Model(inputs=model.input, outputs=output)\n","\n","    new_model.save(\"FExtractor.keras\")\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","    print(new_model.summary())\n"]},{"cell_type":"markdown","metadata":{},"source":["## Voting simulation<br>\n","If the model is already saved, you can start off from here.<br>"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"]}],"source":["import cv2 as cv\n","import pickle\n","\n","from keras.models import load_model\n","from numpy import argmax, array\n","\n","# Loading the feature extractor\n","fextractor = load_model(\"FExtractor.keras\")\n","\n","\n","# Using HOG to extract the facial region\n","face_classifier = cv.CascadeClassifier(cv.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n","\n","def detect_bounding_box(img:cv.Mat):\n","\n","    gray_img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n","\n","    faces = face_classifier.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=4, minSize=(150, 150))\n","\n","    if len(faces) != 0:\n","        for (x, y, w, h) in faces:\n","            to_predict = array([cv.resize(img[y:y+h, x:x+w], (224, 224))])\n","            \n","            # Characteristics vector\n","            prediction = fextractor.predict(to_predict, verbose=0)\n","            \n","        response = prediction\n","    \n","    else:\n","        response = \"No face could be detected\"\n","\n","    return response #, cv.cvtColor(img, cv.COLOR_BGR2RGB)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Enrolment"]},{"cell_type":"markdown","metadata":{},"source":["Here is a simple simulation of the enrolment process "]},{"cell_type":"markdown","metadata":{},"source":["Here, we take a shot our the face.<br>\n","<!--b>The camera will stay opened as long as a clear shot of your face hasn't been taken.</b-->\n","<b>Run this cell as long as a clear shot of your face hasn't been taken.</b>"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["You can go to the next step.\n"]}],"source":["\n","features = \"\"\n","\n","def take_shot():\n","\n","    global features\n","\n","    # While we don't explictly stop the loop\n","    webcam = cv.VideoCapture(0)\n","    features = \"\"\n","\n","    while True:\n","\n","        result, frame = webcam.read()\n","        if not result:\n","            break # Terminate if not read successfully\n","\n","        features = detect_bounding_box(frame)\n","        \n","        cv.imshow(\"Real time facial capture\", frame)\n","\n","        cv.waitKey(0)\n","        # if not isinstance(features, str):\n","        break\n","\n","    webcam.release()\n","    cv.destroyAllWindows()\n","\n","    if isinstance(features, str):\n","        print(features)\n","    else:\n","        features = features[0]\n","        print(\"You can go to the next step.\")\n","\n","    # return features\n","\n","\n","take_shot()\n"]},{"cell_type":"markdown","metadata":{},"source":["We then save the face's characteristics into a file<br>\n","<b>Replace the default name with yours</b>"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["default_name = \"Brel\"\n","\n","try:    # If the file exists\n","\n","    with open(\"voters.data\", \"rb\") as voters_file:\n","        voters = pickle.Unpickler(voters_file).load()\n","        voters[default_name] = {\"features\" : features, \"voted\" : False}\n","\n","        with open(\"voters.data\", \"wb\") as voters_output:\n","            pickle.Pickler(voters_output).dump(voters)\n","\n","except:     # If the file doesn't exist yet\n","    voters = {default_name : {\"features\" : features, \"voted\": False}}\n","    with open(\"voters.data\", \"wb\") as voters_output:\n","        pickle.Pickler(voters_output).dump(voters)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Authentication"]},{"cell_type":"markdown","metadata":{},"source":["Here, we simply take a shot of the voter's face, extract its features and compare it to those already stored.<br>\n","If the face matches with one of the registered voters', the status is checked:\n","* If the voter has not voted yet, his/her status is changed immediately but he/she can have access to the voting room\n","* Else, his/her status doesn't change and he/she can't have access to the voting room\n","\n","If the face doesn't have a match the voter can't have access to the voting room."]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["You can go to the next step.\n"]}],"source":["def euclidian_dist(vect1:list, vect2:list) -> float:\n","    '''\n","        Compute the euclidian distance over two vector of floats.\n","    '''\n","\n","    if len(vect1) != len(vect2):\n","        raise ValueError(f\"Lenght of the vectors should be the same. but vector 1 has lenght {len(vect1)} while vector 2 has lenght {len(vect2)}.\")\n","\n","    v = 0\n","    for _ in range(len(vect1)):\n","        v += (vect1[_] - vect2[_])**2\n","\n","    return v ** 0.5\n","\n","THRESHOLD = 30\n","take_shot()\n"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["No matches found.\n"]}],"source":["\n","with open(\"voters.data\", \"rb\") as voters_file:\n","    voters = pickle.Unpickler(voters_file).load()\n","    \n","    name, status, error = \"\", \"\", 1e36\n","    \n","    for nam, stat in voters.items():\n","        temp_error = euclidian_dist(features, stat[\"features\"])\n","        if temp_error < error:\n","            name, status, error = nam, stat[\"voted\"], temp_error\n","\n","    \n","    if error < THRESHOLD:\n","        if not status:\n","            voters[name][\"voted\"] = True\n","            with open(\"voters.data\", \"wb\") as voters_output:\n","                pickle.Pickler(voters_output).dump(voters)\n","\n","            print(\"The voter is recognized as {} with an error of {:2f}.\\nStatus changed to 'Has voted'.\".format(name, error))\n","\n","        else:\n","            print(\"The voter is recognized as {} with an error of {:2f} and has already voted.\".format(name, error))\n","\n","    \n","    else:\n","        print(\"No matches found.\")"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
